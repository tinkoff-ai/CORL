# CORL (Clean Offline Reinforcement Learning)

[<img src="https://img.shields.io/badge/license-Apache_2.0-blue">](https://github.com/tinkoff-ai/CORL/blob/main/LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)


ðŸ§µ CORL is an Offline Reinforcement Learning library that provides high-quality and easy-to-follow single-file implementations of SOTA ORL algorithms. Each implementation is backed by a research-friendly codebase, allowing you to run or tune thousands of experiments. Heavily inspired by [cleanrl](https://github.com/vwxyzjn/cleanrl) for online RL, check them out too!<br/>

* ðŸ“œ Single-file implementation
* ðŸ“ˆ Benchmarked Implementation for N algorithms
* ðŸ–¼ [Weights and Biases](https://wandb.ai/site) integration


## Getting started

```bash
git clone https://github.com/tinkoff-ai/CORL.git && cd CORL
pip install -r requirements/requirements_dev.txt

# alternatively, you could use docker
docker build -t <image_name> .
docker run gpus=all -it --rm --name <container_name> <image_name>
```


## Algorithms Implemented

| Algorithm      | Variants Implemented | Wandb Report |
| ----------- | ----------- | ----------- |
| âœ… Behavioral Cloning <br>(BC)  |  [`any_percent_bc.py`](algorithms/any_percent_bc.py) |  [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/BC-D4RL-Results--VmlldzoyNzA2MjE1)
| âœ… Behavioral Cloning-10% <br>(BC-10%)  |  [`any_percent_bc.py`](algorithms/any_percent_bc.py) |  [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/BC-10-D4RL-Results--VmlldzoyNzEwMjcx)
| âœ… [Conservative Q-Learning for Offline Reinforcement Learning <br>(CQL)](https://arxiv.org/abs/2006.04779)  |  [`cql.py`](algorithms/cql.py) | [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/CQL-D4RL-Results--VmlldzoyNzA2MTk5)
| âœ… [Accelerating Online Reinforcement Learning with Offline Datasets <br>(AWAC)](https://arxiv.org/abs/2006.09359)  |  [`awac.py`](algorithms/awac.py) | [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/AWAC-D4RL-Results--VmlldzoyNzA2MjE3)
| âœ… [Offline Reinforcement Learning with Implicit Q-Learning <br>(IQL)](https://arxiv.org/abs/2110.06169)  |  [`iql.py`](algorithms/iql.py) | [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/IQL-D4RL-Results--VmlldzoyNzA2MTkx)
| âœ… [A Minimalist Approach to Offline Reinforcement Learning <br>(TD3+BC)](https://arxiv.org/abs/2106.06860)  |  [`td3_bc.py`](algorithms/td3_bc.py) | [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/TD3-BC-D4RL-Results--VmlldzoyNzA2MjA0)
| âœ… [Decision Transformer: Reinforcement Learning via Sequence Modeling <br>(DT)](https://arxiv.org/abs/2106.01345)  |  [`dt.py`](algorithms/dt.py) | [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/DT-D4RL-Results--VmlldzoyNzA2MTk3)
| âœ… [Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble <br>(SAC-N)](https://arxiv.org/abs/2110.01548)  |  [`sac_n.py`](algorithms/sac_n.py) | [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/SAC-N-D4RL-Results--VmlldzoyNzA1NTY1)
| âœ… [Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble <br>(EDAC)](https://arxiv.org/abs/2110.01548)  |  [`edac.py`](algorithms/edac.py) | [`Gym-MuJoCo, Maze2D`](https://wandb.ai/tlab/CORL/reports/EDAC-D4RL-Results--VmlldzoyNzA5ODUw)

## D4RL Benchmarks
For learning curves and all the details, you can check the links above. Here, we report reproduced **final** and **best** scores. Note that thay differ by a big margin, and some papers may use different approaches not making it always explicit which one reporting methodology they chose.

### Last Scores
#### Gym-MuJoCo
| **Task-Name**|BC|BC-10%|TD3 + BC|CQL|IQL|AWAC|SAC-N|EDAC|DT |
|------------------------------|------------|--------|--------|-----|-----|------|-------|------|----|
|halfcheetah-medium-v2 | 42.40Â±0.21 | 42.46Â±0.81 | 48.10Â±0.21 | 46.64Â±0.24 | 48.31Â±0.11 | 49.94Â±0.37 | 68.20Â±1.48 | 67.70Â±1.20 | 42.20Â±0.30|
|halfcheetah-medium-expert-v2 | 55.95Â±8.49 | 90.10Â±2.83 | 90.78Â±6.98 | 87.10Â±11.41 | 94.55Â±0.21 | 95.41Â±0.89 | 98.96Â±10.74 | 104.76Â±0.74 | 91.55Â±1.10|
|halfcheetah-medium-replay-v2 | 35.66Â±2.68 | 23.59Â±8.02 | 44.84Â±0.68 | 44.67Â±0.28 | 43.53Â±0.43 | 44.85Â±0.81 | 60.70Â±1.17 | 62.06Â±1.27 | 38.91Â±0.57|
|hopper-medium-v2 | 53.51Â±2.03 | 55.48Â±8.43 | 60.37Â±4.03 | 56.88Â±4.46 | 62.75Â±6.02 | 66.45Â±11.04 | 40.82Â±11.44 | 101.70Â±0.32 | 65.10Â±1.86|
|hopper-medium-expert-v2 | 52.30Â±4.63 | 111.16Â±1.19 | 101.17Â±10.48 | 86.95Â±17.45 | 106.24Â±6.09 | 105.16Â±7.05 | 101.31Â±13.43 | 105.19Â±11.64 | 110.44Â±0.39|
|hopper-medium-replay-v2 | 29.81Â±2.39 | 70.42Â±9.99 | 64.42Â±24.84 | 84.21Â±18.27 | 84.57Â±13.49 | 99.11Â±1.99 | 100.33Â±0.90 | 99.66Â±0.94 | 81.77Â±7.93|
|walker2d-medium-v2 | 63.23Â±18.76 | 67.34Â±5.97 | 82.71Â±5.51 | 80.58Â±3.80 | 84.03Â±5.42 | 69.39Â±31.97 | 87.47Â±0.76 | 93.36Â±1.60 | 67.63Â±2.93|
|walker2d-medium-expert-v2 | 98.96Â±18.45 | 108.70Â±0.29 | 110.03Â±0.41 | 110.23Â±0.48 | 111.68Â±0.56 | 111.06Â±2.33 | 114.93Â±0.48 | 114.75Â±0.86 | 107.11Â±1.11|
|walker2d-medium-replay-v2 | 21.80Â±11.72 | 54.35Â±7.32 | 85.62Â±4.63 | 82.16Â±2.32 | 82.55Â±8.00 | 81.50Â±2.68 | 78.99Â±0.58 | 87.10Â±3.21 | 59.86Â±3.15|
|                              |            |        |        |     |     |      |       |      |    |
| **locomotion average**       |50.40 | 69.29 | 76.45 | 75.49 | 79.80 | 80.32 | 83.52 | 92.92 | 73.84 |

#### Maze2d
| **Task-Name**|BC|BC-10%|TD3 + BC|CQL|IQL|AWAC|SAC-N|EDAC|DT |
|------------------------------|------------|--------|--------|-----|-----|------|-------|------|----|
|maze2d-umaze-v1 | 0.36Â±10.03 | 12.18Â±4.95 | 29.41Â±14.22 | -6.97Â±17.41 | 37.69Â±1.99 | 57.89Â±15.85 | 124.03Â±18.93 | 95.57Â±7.36 | 18.08Â±29.35|
|maze2d-medium-v1 | 0.79Â±3.76 | 14.25Â±2.69 | 59.45Â±41.86 | 2.77Â±7.24 | 35.45Â±0.98 | 78.84Â±45.94 | 88.59Â±21.45 | 55.07Â±8.18 | 31.71Â±30.40|
|maze2d-large-v1 | 2.26Â±5.07 | 11.32Â±5.88 | 97.10Â±29.34 | 1.29Â±7.11 | 49.64Â±22.02 | 190.03Â±55.34 | 204.85Â±0.93 | 93.27Â±8.93 | 35.66Â±32.56|
|                              |            |        |        |     |     |      |       |      |    |
| **maze2d average**           | 1.13 | 12.58 | 61.99 | -0.97 | 40.92 | 108.92 | 139.16 | 81.30 | 28.48 |

#### Antmaze
| **Task-Name**|BC|BC-10%|TD3 + BC|CQL|IQL|AWAC|SAC-N|EDAC|DT |
|------------------------------|------------|--------|--------|-----|-----|------|-------|------|----|
|antmaze-umaze-v0 | 51.50Â±8.81 | 67.75Â±6.40 | 93.25Â±1.50 | 63.75Â±8.26 | 74.50Â±11.03 | 63.50Â±9.33 | 0.00Â±0.00 | 29.25Â±33.35 | 51.75Â±11.76|
|antmaze-medium-play-v0 | 0.00Â±0.00 | 2.50Â±1.91 | 0.00Â±0.00 | 0.00Â±0.00 | 71.50Â±12.56 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00|
|antmaze-large-play-v0 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 40.75Â±12.69 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00|
|                              |            |        |        |     |     |      |       |      |    |
| **antmaze average**           | 17.17 | 23.42 | 31.08 | 21.25 | 62.25 | 21.17 | 0.00 | 9.75 | 17.25 |

### Best Scores
#### Gym-MuJoCo
| **Task-Name**|BC|BC-10%|TD3 + BC|CQL|IQL|AWAC|SAC-N|EDAC|DT |
|------------------------------|------------|--------|--------|-----|-----|------|-------|------|----|
|halfcheetah-medium-v2 | 43.60Â±0.16 | 43.90Â±0.15 | 48.93Â±0.13 | 47.26Â±0.23 | 48.77Â±0.06 | 50.87Â±0.21 | 72.21Â±0.35 | 69.72Â±1.06 | 42.73Â±0.11|
|halfcheetah-medium-expert-v2 | 79.69Â±3.58 | 94.11Â±0.25 | 96.59Â±1.01 | 95.82Â±0.31 | 95.83Â±0.38 | 96.86Â±0.29 | 111.73Â±0.55 | 110.62Â±1.20 | 93.40Â±0.25|
|halfcheetah-medium-replay-v2 | 40.52Â±0.22 | 42.27Â±0.53 | 45.84Â±0.30 | 45.97Â±0.32 | 45.06Â±0.16 | 46.57Â±0.27 | 67.29Â±0.39 | 66.55Â±1.21 | 40.31Â±0.32|
|hopper-medium-v2 | 69.04Â±3.35 | 73.84Â±0.43 | 70.44Â±1.37 | 69.09Â±0.85 | 80.74Â±1.27 | 99.07Â±1.45 | 101.79Â±0.23 | 103.26Â±0.16 | 69.42Â±4.21|
|hopper-medium-expert-v2 | 90.63Â±12.68 | 113.13Â±0.19 | 113.22Â±0.50 | 111.01Â±1.93 | 111.79Â±0.47 | 113.30Â±0.72 | 111.24Â±0.17 | 111.80Â±0.13 | 111.18Â±0.24|
|hopper-medium-replay-v2 | 68.88Â±11.93 | 90.57Â±2.38 | 98.12Â±1.34 | 102.10Â±0.41 | 102.33Â±0.44 | 101.52Â±0.32 | 103.83Â±0.61 | 103.28Â±0.57 | 88.74Â±3.49|
|walker2d-medium-v2 | 80.64Â±1.06 | 82.05Â±1.08 | 86.91Â±0.32 | 84.76Â±0.15 | 87.99Â±0.83 | 86.04Â±4.46 | 90.17Â±0.63 | 95.78Â±1.23 | 74.70Â±0.64|
|walker2d-medium-expert-v2 | 109.95Â±0.72 | 109.90Â±0.10 | 112.21Â±0.07 | 111.70Â±0.28 | 113.19Â±0.33 | 113.14Â±2.38 | 116.93Â±0.49 | 116.52Â±0.86 | 108.71Â±0.39|
|walker2d-medium-replay-v2 | 48.41Â±8.78 | 76.09Â±0.47 | 91.17Â±0.83 | 88.02Â±1.18 | 91.85Â±2.26 | 86.53Â±0.93 | 85.18Â±1.89 | 89.69Â±1.60 | 68.22Â±1.39|
|                              |            |        |        |     |     |      |       |      |    |
| **locomotion average**       |    70.15 | 80.65 | 84.83 | 83.97 | 86.40 | 88.21 | 95.60 | 96.36 | 77.49 |


#### Maze2d
| **Task-Name**|BC|BC-10%|TD3 + BC|CQL|IQL|AWAC|SAC-N|EDAC|DT |
|------------------------------|------------|--------|--------|-----|-----|------|-------|------|----|
|maze2d-umaze-v1 | 16.09Â±1.00 | 22.49Â±1.75 | 99.33Â±18.66 | 18.82Â±0.63 | 44.04Â±3.02 | 138.21Â±12.42 | 151.69Â±7.48 | 145.53Â±3.55 | 63.83Â±20.04|
|maze2d-medium-v1 | 19.16Â±1.44 | 27.64Â±2.16 | 150.93Â±4.50 | 17.96Â±5.24 | 92.25Â±40.74 | 158.72Â±11.81 | 93.58Â±16.80 | 152.74Â±1.39 | 68.14Â±14.15|
|maze2d-large-v1 | 20.75Â±7.69 | 41.83Â±4.20 | 197.64Â±6.07 | 12.27Â±5.34 | 138.70Â±44.70 | 227.04Â±1.79 | 206.90Â±1.04 | 180.78Â±3.71 | 50.25Â±22.33|
|                              |            |        |        |     |     |      |       |      |    |
| **maze2d average**           | 18.67 | 30.65 | 149.30 | 16.35 | 91.66 | 174.66 | 150.72 | 159.68 | 60.74 |

#### Antmaze
| **Task-Name**|BC|BC-10%|TD3 + BC|CQL|IQL|AWAC|SAC-N|EDAC|DT |
|------------------------------|------------|--------|--------|-----|-----|------|-------|------|----|
|antmaze-umaze-v0 | 71.25Â±9.07 | 79.50Â±2.38 | 97.75Â±1.50 | 76.75Â±4.99 | 87.00Â±2.94 | 74.75Â±8.77 | 0.00Â±0.00 | 75.00Â±27.51 | 60.50Â±3.11|
|antmaze-medium-play-v0 | 4.75Â±2.22 | 8.50Â±3.51 | 6.00Â±2.00 | 1.75Â±0.96 | 86.00Â±2.16 | 14.00Â±11.80 | 0.00Â±0.00 | 0.00Â±0.00 | 0.25Â±0.50|
|antmaze-large-play-v0 | 0.75Â±0.50 | 11.75Â±2.22 | 0.50Â±0.58 | 0.00Â±0.00 | 53.00Â±6.83 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00|
|                              |            |        |        |     |     |      |       |      |    |
| **antmaze average**           | 25.58 | 33.25 | 34.75 | 26.17 | 75.33 | 29.58 | 0.00 | 25.00 | 20.25 |

## Citing CORL

If you use CORL in your work, please use the following bibtex
```bibtex
@misc{corl2022,
  author={Tarasov, Denis and Nikulin, Alexander and Akimov, Dmitriy and Kurenkov, Vladislav and Sergey Kolesnikov},
  title={CORL: Research-oriented Deep Offline Reinforcement Learning Library},
  year={2022},
  url={https://github.com/tinkoff-ai/CORL},
}
```
